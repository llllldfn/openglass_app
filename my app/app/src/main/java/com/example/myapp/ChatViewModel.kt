package com.example.myapp

import android.app.Application
import android.util.Log
import androidx.camera.view.PreviewView
import androidx.lifecycle.AndroidViewModel
import androidx.lifecycle.LifecycleOwner
import androidx.lifecycle.viewModelScope
import com.example.myapp.data.repository.AiRepository
import com.example.myapp.data.repository.InputData
import com.example.myapp.data.repository.LoadState
import com.example.myapp.input.audio.AudioInput
import com.example.myapp.input.ble.BleInput
import com.example.myapp.input.camera.CameraInput
import com.example.myapp.model.ChatMessage
import com.example.myapp.model.Role
import com.example.myapp.output.tts.TtsManager
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.Job
import kotlinx.coroutines.isActive
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import androidx.lifecycle.Observer
import com.example.myapp.model.AiResponse
import android.media.AudioRecord
import android.media.AudioFormat
import android.media.MediaRecorder
import java.io.ByteArrayOutputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import android.content.Context
import android.media.AudioManager

data class ChatUiState(
	val messages: List<ChatMessage> = emptyList(),
	val inputText: String = "",
	val error: String? = null,
	val cameraOn: Boolean = false,
	val cameraMode: String = "æ‰‹æœºç›¸æœº", // æ–°å¢ç›¸æœºæ¨¡å¼
	val audioOn: Boolean = false,
	val bleOn: Boolean = false,
	val ttsOn: Boolean = true,
	val lastImageTimestampMs: Long? = null,
	val lastAudioTimestampMs: Long? = null,
	val bleConnectionState: com.example.myapp.input.ble.BleConnectionState = com.example.myapp.input.ble.BleConnectionState(),
	val audioUploadEnabled: Boolean = false,  // æ–°å¢éŸ³é¢‘ä¸Šä¼ å¼€å…³
	val blePhotoPreview: ByteArray? = null,  // æ–°å¢è“ç‰™å›¾ç‰‡é¢„è§ˆ
	val blePhotoTimestamp: Long? = null
 
)

class ChatViewModel(
	application: Application,
	private val repository: AiRepository,
	private val tts: TtsManager
) : AndroidViewModel(application) {
	private val _ui = MutableStateFlow(ChatUiState())
	val ui: StateFlow<ChatUiState> = _ui.asStateFlow()

	private val camera = CameraInput(getApplication())
	private val audio = AudioInput(getApplication())
	private val ble = BleInput(getApplication())

	private fun newUuid(): String = java.util.UUID.randomUUID().toString()

	private var cameraJob: Job? = null
	private var audioJob: Job? = null
	private var bleJob: Job? = null

    // Phone recording state
    private var phoneRecorder: AudioRecord? = null
    private var phoneRecJob: Job? = null
    private var phoneRecBuffer: ByteArrayOutputStream? = null
    private var phoneSampleRate = 16000

    // Device recording state
    private var deviceRecJob: Job? = null
	
	private var isTakingPhoto = false
	
	init {
		// ç›‘å¬è“ç‰™å›¾ç‰‡æ•°æ®æµ
		viewModelScope.launch(Dispatchers.IO) {
			ble.photoData.collect { imageBytes ->
				Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ“¸ BLE_PHOTO_STREAM: æ”¶åˆ°è“ç‰™å›¾ç‰‡æ•°æ®æµ ${imageBytes.size} bytes")
				processBleImage(imageBytes)
			}
		}
	}
	
	private suspend fun processBleImage(imageBytes: ByteArray) {
		Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ”„ BLE_PHOTO_PROCESS: æ”¶åˆ°å®Œæ•´è“ç‰™å›¾ç‰‡ ${imageBytes.size} bytes")
		
		// æ‰“å°å›¾ç‰‡æ•°æ®çš„å‰å‡ ä¸ªå­—èŠ‚ç”¨äºè°ƒè¯•
		if (imageBytes.size > 0) {
			val hexString = imageBytes.take(16).joinToString("") { "%02X".format(it) }
			Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ” BLE_PHOTO_PROCESS: æ”¶åˆ°å›¾ç‰‡å‰16å­—èŠ‚: $hexString")
		}
		
		// BleInputå·²ç»ç»„è£…å¥½äº†å®Œæ•´å›¾ç‰‡ï¼Œç›´æ¥å¤„ç†
		processCompleteBleImage(imageBytes)
	}
	
	private suspend fun processCompleteBleImage(completeImage: ByteArray) {
		Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ–¼ï¸ BLE_PHOTO_PROCESS: å¤„ç†å®Œæ•´è“ç‰™å›¾ç‰‡ ${completeImage.size} bytes")
		
		// å›¾ç‰‡å·²ç»åœ¨BleInputä¸­ç»„è£…å®Œæˆï¼Œç›´æ¥ä½¿ç”¨
		Log.i("[PHOTO_PREVIEW] ChatViewModel", "âœ… BLE_PHOTO_PROCESS: å›¾ç‰‡æ•°æ®å·²å°±ç»ªï¼Œæ€»å¤§å°: ${completeImage.size} bytes")
		
		// éªŒè¯å›¾ç‰‡æ•°æ®
		val isValid = com.example.myapp.utils.ImageUtils.isValidImage(completeImage)
		val imageInfo = com.example.myapp.utils.ImageUtils.getImageInfo(completeImage)
		Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ” BLE_PHOTO_PROCESS: å›¾ç‰‡éªŒè¯ç»“æœ: $isValid, å›¾ç‰‡ä¿¡æ¯: $imageInfo")
		
		// æ£€æŸ¥å›¾ç‰‡å¤§å°æ˜¯å¦åˆç† - 2180 byteså¯¹äºOpenGlassæ¥è¯´å®Œå…¨æ­£å¸¸
		if (completeImage.size < 500) { // é™ä½åˆ°500 bytesï¼Œå› ä¸ºOpenGlassçš„å›¾ç‰‡é€šå¸¸è¾ƒå°
			Log.e("[PHOTO_PREVIEW] ChatViewModel", "âŒ BLE_PHOTO_PROCESS: å›¾ç‰‡å¤ªå° (${completeImage.size} bytes)ï¼Œå¯èƒ½åªåŒ…å«JPEGå¤´")
			_ui.value = _ui.value.copy(error = "è“ç‰™å›¾ç‰‡æ•°æ®å¤ªå° (${completeImage.size} bytes)ï¼Œè¯·é‡æ–°æ‹ç…§")
			return
		}
		
		// ä¿å­˜å›¾ç‰‡é¢„è§ˆ
		_ui.value = _ui.value.copy(
			blePhotoPreview = completeImage,
			blePhotoTimestamp = System.currentTimeMillis()
		)
		Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ–¼ï¸ BLE_PHOTO_PROCESS: å›¾ç‰‡é¢„è§ˆå·²ä¿å­˜åˆ°UIçŠ¶æ€")
		
		// å¼ºåˆ¶åˆ·æ–°UIçŠ¶æ€
		viewModelScope.launch(Dispatchers.Main) {
			// å»¶è¿Ÿä¸€ä¸‹ç¡®ä¿çŠ¶æ€æ›´æ–°
			kotlinx.coroutines.delay(100)
			// å†æ¬¡ç¡®è®¤çŠ¶æ€
			Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ”„ UIçŠ¶æ€ç¡®è®¤: blePhotoPreview=${_ui.value.blePhotoPreview?.size ?: "null"} bytes, blePhotoTimestamp=${_ui.value.blePhotoTimestamp}")
		}
		
		// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯æ˜¾ç¤ºæ”¶åˆ°å›¾ç‰‡
		val userMessage = ChatMessage(
			id = System.currentTimeMillis().toString(),
			role = Role.User,
			text = "ğŸ“· è“ç‰™æ‹ç…§å®Œæˆ (${completeImage.size} bytes)"
		)
		_ui.value = _ui.value.copy(messages = _ui.value.messages + userMessage)
		
		// å‘é€å›¾ç‰‡ç»™AIå¤„ç†
		try {
			Log.i("[PHOTO_PREVIEW] ChatViewModel", "ğŸ¤– BLE_PHOTO_PROCESS: å‘é€å®Œæ•´å›¾ç‰‡ç»™AIå¤„ç†")
			val live = repository.sendToAi(InputData.Image(completeImage), getApplication())
			val observer = object : Observer<LoadState<AiResponse>> {
				override fun onChanged(state: LoadState<AiResponse>) {
					when (state) {
						is LoadState.Success -> {
							val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
							Log.i("[PHOTO_PREVIEW] ChatViewModel", "âœ… BLE_PHOTO_PROCESS: AIå¤„ç†æˆåŠŸï¼Œå›å¤é•¿åº¦: ${replyText.length}")
							val reply = ChatMessage(
								id = System.currentTimeMillis().toString(), 
								role = Role.Assistant, 
								text = replyText
							)
							_ui.value = _ui.value.copy(messages = _ui.value.messages + reply)
							if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
							live.removeObserver(this)
						}
						is LoadState.Error -> {
							Log.e("[PHOTO_PREVIEW] ChatViewModel", "âŒ BLE_PHOTO_PROCESS: AIå¤„ç†å¤±è´¥: ${state.throwable.message}", state.throwable)
							_ui.value = _ui.value.copy(error = "AIå¤„ç†å¤±è´¥: ${state.throwable.message}")
							live.removeObserver(this)
						}
						is LoadState.Loading -> {
							Log.d("[PHOTO_PREVIEW] ChatViewModel", "â³ BLE_PHOTO_PROCESS: AIå¤„ç†ä¸­...")
						}
					}
				}
			}
			viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
		} catch (e: Exception) {
			Log.e("[PHOTO_PREVIEW] ChatViewModel", "ğŸ’¥ BLE_PHOTO_PROCESS: AIå¤„ç†å¼‚å¸¸", e)
			_ui.value = _ui.value.copy(error = "AIå¤„ç†å¼‚å¸¸: ${e.message}")
		}
	}

	fun bindCamera(owner: LifecycleOwner, preview: PreviewView) {
		viewModelScope.launch(Dispatchers.Main) {
			runCatching { camera.bind(owner, preview) }
				.onSuccess {
					// ç»‘å®šæˆåŠŸåå†å¯åŠ¨ç›¸æœºå¾ªç¯
					if (_ui.value.cameraOn && _ui.value.cameraMode == "æ‰‹æœºç›¸æœº") {
						startCameraLoop()
					}
				}
				.onFailure { e -> _ui.value = _ui.value.copy(error = e.message) }
		}
	}

	fun setCameraEnabled(enabled: Boolean) {
		_ui.value = _ui.value.copy(cameraOn = enabled)
		// ç§»é™¤è¿™é‡Œçš„è‡ªåŠ¨å¯åŠ¨ç›¸æœºå¾ªç¯é€»è¾‘ï¼Œç”± bindCamera æˆåŠŸåè§¦å‘
	}
	
	fun clearBlePhotoPreview() {
		_ui.value = _ui.value.copy(
			blePhotoPreview = null,
			blePhotoTimestamp = null
		)
	}
	
	fun onCameraPermissionGranted() {
		Log.d("[PHOTO_PREVIEW] ChatViewModel", "ç›¸æœºæƒé™å·²æˆäºˆï¼Œå¯ä»¥å¯åŠ¨ç›¸æœºé¢„è§ˆ")
		// å¦‚æœç›¸æœºæ¨¡å¼æ˜¯æ‰‹æœºç›¸æœºä¸”ç›¸æœºå·²å¯ç”¨ï¼Œå°è¯•é‡æ–°ç»‘å®šç›¸æœº
		if (_ui.value.cameraMode == "æ‰‹æœºç›¸æœº" && _ui.value.cameraOn) {
			Log.d("[PHOTO_PREVIEW] ChatViewModel", "å°è¯•é‡æ–°ç»‘å®šç›¸æœºé¢„è§ˆ")
			// è¿™é‡Œä¸éœ€è¦ç«‹å³ç»‘å®šï¼Œå› ä¸ºLaunchedEffectä¼šå¤„ç†
		}
	}
	
	fun takePhonePhoto() {
		if (isTakingPhoto) return
		isTakingPhoto = true
		Log.d("[PHOTO_PREVIEW] ChatViewModel", "ğŸ“¸ å¼€å§‹æ‰‹æœºæ‹ç…§")
		viewModelScope.launch(Dispatchers.IO) {
			try {
				val photoData = camera.captureJpegOnce()
				Log.d("[PHOTO_PREVIEW] ChatViewModel", "ğŸ“¸ æ‰‹æœºæ‹ç…§æˆåŠŸï¼Œå›¾ç‰‡å¤§å°: ${photoData.size} bytes")
				
				// å‘é€å›¾ç‰‡ç»™AIå¤„ç†
				val live = repository.sendToAi(InputData.Image(photoData), getApplication())
				val observer = object : Observer<LoadState<AiResponse>> {
					override fun onChanged(state: LoadState<AiResponse>) {
						when (state) {
							is LoadState.Loading -> { /* å¯é€‰ï¼šæ˜¾ç¤ºloading */ }
							is LoadState.Success, is LoadState.Error -> {
								isTakingPhoto = false // å¤„ç†å®Œæ¯•åå…è®¸å†æ¬¡æ‹ç…§
								live.removeObserver(this)
							}
						}
					}
				}
				live.observeForever(observer)
			} catch (e: Exception) {
				isTakingPhoto = false
			}
		}
	}
	
	fun setCameraMode(mode: String) {
		_ui.value = _ui.value.copy(cameraMode = mode)
		// å¦‚æœç›¸æœºå·²å¯ç”¨ï¼Œæ ¹æ®æ–°æ¨¡å¼è°ƒæ•´
		if (_ui.value.cameraOn) {
			if (mode == "æ‰‹æœºç›¸æœº") {
				startCameraLoop()
			} else {
				stopCameraLoop()
			}
		}
	}

	fun setBleEnabled(enabled: Boolean) {
		_ui.value = _ui.value.copy(bleOn = enabled)
		if (enabled) startBleLoop() else stopBleLoop()
	}

	private fun startBleLoop() {
		bleJob?.cancel()
		
		// å¯åŠ¨çŠ¶æ€ç›‘å¬
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				ble.connectionState.collect { state ->
					Log.d("ChatViewModel", "BLEè¿æ¥çŠ¶æ€æ›´æ–°: isConnected=${state.isConnected}, deviceName=${state.deviceName}, error=${state.error}")
					_ui.value = _ui.value.copy(bleConnectionState = state)
					
					when {
						state.isScanning -> {
							_ui.value = _ui.value.copy(error = "æ­£åœ¨æ‰«æOpenGlassè®¾å¤‡...")
						}
						state.isConnected -> {
							_ui.value = _ui.value.copy(error = "å·²è¿æ¥åˆ°è®¾å¤‡: ${state.deviceName}")
							// è¿æ¥æˆåŠŸæ—¶è‡ªåŠ¨æ‰“å¼€è“ç‰™å¼€å…³
							_ui.value = _ui.value.copy(bleOn = true)
						}
						state.error != null -> {
							_ui.value = _ui.value.copy(error = "è“ç‰™é”™è¯¯: ${state.error}")
							_ui.value = _ui.value.copy(bleOn = false)
						}
					}
				}
			}.onFailure { e -> 
				Log.e("ChatViewModel", "BLEçŠ¶æ€ç›‘å¬å¤±è´¥", e)
				_ui.value = _ui.value.copy(error = e.message, bleOn = false) 
			}
		}
		
		// å¯åŠ¨æ•°æ®æ¥æ”¶ï¼ˆç°åœ¨åªè´Ÿè´£è¿æ¥ï¼Œå›¾ç‰‡æ•°æ®é€šè¿‡photoDataæµå¤„ç†ï¼‰
		bleJob = viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				ble.scanAndConnect("OpenGlass").collect { bytes ->
					// æ³¨æ„ï¼šç°åœ¨å›¾ç‰‡æ•°æ®é€šè¿‡photoDataæµå¤„ç†ï¼Œè¿™é‡Œåªå¤„ç†éŸ³é¢‘æ•°æ®
					// éŸ³é¢‘æ•°æ®æ¥è‡ªAUDIO_CHAR_UUID
					
					// åªå¤„ç†éŸ³é¢‘æ•°æ®
					if (bytes.size <= 1000 && _ui.value.audioUploadEnabled) {
						Log.i("ChatViewModel", "ğŸµ BLE_AUDIO: æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ® ${bytes.size} å­—èŠ‚")
						val message = ChatMessage(
							id = System.currentTimeMillis().toString(),
							role = Role.User,
							text = "ğŸµ æ”¶åˆ°è“ç‰™éŸ³é¢‘æ•°æ®: ${bytes.size} å­—èŠ‚"
						)
						_ui.value = _ui.value.copy(messages = _ui.value.messages + message)
						
						// å‘é€éŸ³é¢‘ç»™AIå¤„ç†
						try {
							val live = repository.sendToAi(InputData.Audio(bytes), getApplication())
							val observer = object : Observer<LoadState<AiResponse>> {
								override fun onChanged(state: LoadState<AiResponse>) {
									when (state) {
										is LoadState.Success -> {
											val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
											val reply = ChatMessage(id = System.currentTimeMillis().toString(), role = Role.Assistant, text = replyText)
											_ui.value = _ui.value.copy(messages = _ui.value.messages + reply)
											if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
											live.removeObserver(this)
										}
										is LoadState.Error -> { 
											_ui.value = _ui.value.copy(error = "AIå¤„ç†å¤±è´¥: ${state.throwable.message}")
											live.removeObserver(this) 
										}
										is LoadState.Loading -> {
											Log.d("ChatViewModel", "AIå¤„ç†ä¸­...")
										}
									}
								}
							}
							viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
						} catch (e: Exception) {
							_ui.value = _ui.value.copy(error = "AIå¤„ç†å¼‚å¸¸: ${e.message}")
						}
					} else {
						// å¦‚æœéŸ³é¢‘ä¸Šä¼ å…³é—­ï¼Œåˆ™ä¸æ˜¾ç¤ºä»»ä½•æ¶ˆæ¯ï¼Œåªè®°å½•æ—¥å¿—
						Log.d("ChatViewModel", "éŸ³é¢‘æ•°æ®å·²å¿½ç•¥: ${bytes.size} å­—èŠ‚")
				}
				}
			}.onFailure { e -> 
				_ui.value = _ui.value.copy(error = "è“ç‰™è¿æ¥å¤±è´¥: ${e.message}")
				_ui.value = _ui.value.copy(bleOn = false)
			}
		}
	}

	private fun stopBleLoop() { 
		bleJob?.cancel(); 
		bleJob = null 
		ble.disconnect() // æ–­å¼€è“ç‰™è¿æ¥
	}

	fun setTtsEnabled(enabled: Boolean) {
		Log.d("[PHOTO_PREVIEW] ChatViewModel", "ğŸ”Š TTSçŠ¶æ€åˆ‡æ¢: ${_ui.value.ttsOn} -> $enabled")
		_ui.value = _ui.value.copy(ttsOn = enabled)
		
		// å¦‚æœå…³é—­TTSï¼Œç«‹å³åœæ­¢å½“å‰æ’­æ”¾
		if (!enabled) {
			tts.stop()
			Log.d("[PHOTO_PREVIEW] ChatViewModel", "ğŸ”Š TTSå·²å…³é—­ï¼Œåœæ­¢å½“å‰æ’­æ”¾")
		}
		
		Log.d("[PHOTO_PREVIEW] ChatViewModel", "ğŸ”Š TTSçŠ¶æ€å·²æ›´æ–°: ${_ui.value.ttsOn}")
	}
	
	fun clearError() {
		_ui.value = _ui.value.copy(error = null)
	}

	// æ–°å¢åŠŸèƒ½æ–¹æ³•
	fun takePhoto() {
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				// è¿™é‡Œåº”è¯¥è°ƒç”¨ç›¸æœºçš„æ‹ç…§æ–¹æ³•ï¼Œæš‚æ—¶ç”¨æ³¨é‡Šæ›¿ä»£
				// camera.takePhoto()?.let { photo ->
				// 	_ui.value = _ui.value.copy(lastImageTimestampMs = System.currentTimeMillis())
				// 	val live = repository.sendToAi(InputData.Image(photo), getApplication())
				// 	// ... å¤„ç†æ‹ç…§ç»“æœ
				// }
				_ui.value = _ui.value.copy(error = "æ‹ç…§åŠŸèƒ½æš‚æœªå®ç°")
			}.onFailure { e -> _ui.value = _ui.value.copy(error = "æ‹ç…§å¤±è´¥: ${e.message}") }
		}
	}
	
	fun takeBlePhoto() {
		if (_ui.value.bleOn && _ui.value.bleConnectionState.isConnected) {
			Log.i("ChatViewModel", "ğŸš€ BLE_PHOTO_TRIGGER: ç”¨æˆ·è§¦å‘è“ç‰™æ‹ç…§")
			ble.takePhoto()
			_ui.value = _ui.value.copy(error = "ğŸ“¸ å·²è§¦å‘è“ç‰™è®¾å¤‡æ‹ç…§ï¼Œç­‰å¾…å›¾ç‰‡æ•°æ®...")
			
			// å¯åŠ¨è“ç‰™æ•°æ®æ¥æ”¶å¾ªç¯ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å¯åŠ¨ï¼‰
			if (bleJob?.isActive != true) {
				Log.d("ChatViewModel", "ğŸ”„ BLE_PHOTO_TRIGGER: å¯åŠ¨è“ç‰™æ•°æ®æ¥æ”¶å¾ªç¯")
				startBleLoop()
			}
		} else {
			Log.w("ChatViewModel", "âš ï¸ BLE_PHOTO_TRIGGER: è“ç‰™æœªè¿æ¥æˆ–æœªå¯ç”¨")
			_ui.value = _ui.value.copy(error = "è“ç‰™æœªè¿æ¥æˆ–æœªå¯ç”¨")
		}
	}
	
	fun setAudioUploadEnabled(enabled: Boolean) {
		_ui.value = _ui.value.copy(audioUploadEnabled = enabled)
	}

	fun startRecording() {
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				// audio.startRecording()
				_ui.value = _ui.value.copy(audioOn = true)
				_ui.value = _ui.value.copy(error = "å½•éŸ³åŠŸèƒ½æš‚æœªå®ç°")
			}.onFailure { e -> _ui.value = _ui.value.copy(error = "å¼€å§‹å½•éŸ³å¤±è´¥: ${e.message}") }
		}
	}

	fun stopRecording() {
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				// audio.stopRecording()?.let { audioData ->
				// 	_ui.value = _ui.value.copy(lastAudioTimestampMs = System.currentTimeMillis())
				// 	val live = repository.sendToAi(InputData.Audio(audioData), getApplication())
				// 	// ... å¤„ç†å½•éŸ³ç»“æœ
				// }
				_ui.value = _ui.value.copy(audioOn = false)
			}.onFailure { e -> _ui.value = _ui.value.copy(error = "åœæ­¢å½•éŸ³å¤±è´¥: ${e.message}") }
		}
	}



	fun startVoiceInput() {
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				// audio.startVoiceInput()
				_ui.value = _ui.value.copy(audioOn = true)
				_ui.value = _ui.value.copy(error = "è¯­éŸ³è¾“å…¥åŠŸèƒ½æš‚æœªå®ç°")
			}.onFailure { e -> _ui.value = _ui.value.copy(error = "å¼€å§‹è¯­éŸ³è¾“å…¥å¤±è´¥: ${e.message}") }
		}
	}

	fun stopVoiceInput() {
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				// audio.stopVoiceInput()?.let { audioData ->
				// 	_ui.value = _ui.value.copy(lastAudioTimestampMs = System.currentTimeMillis())
				// 	val live = repository.sendToAi(InputData.Audio(audioData), getApplication())
				// 	// ... å¤„ç†è¯­éŸ³è¾“å…¥ç»“æœ
				// }
				_ui.value = _ui.value.copy(audioOn = false)
			}.onFailure { e -> _ui.value = _ui.value.copy(error = "åœæ­¢è¯­éŸ³è¾“å…¥å¤±è´¥: ${e.message}") }
		}
	}

    // ===== Phone recording (press-and-hold) =====
    fun startPhoneRecording() {
        if (phoneRecJob?.isActive == true) return
        viewModelScope.launch(Dispatchers.IO) {
            try {
                Log.i("ChatVM", "[AUDIO_REC] ğŸ™ï¸ å¼€å§‹æ‰‹æœºå½•éŸ³: targetSampleRate=$phoneSampleRate")
                // æƒé™æ£€æŸ¥
                val hasPerm = androidx.core.content.ContextCompat.checkSelfPermission(
                    getApplication(), android.Manifest.permission.RECORD_AUDIO
                ) == android.content.pm.PackageManager.PERMISSION_GRANTED
                if (!hasPerm) {
                    Log.w("ChatVM", "[AUDIO_REC] ç¼ºå°‘ RECORD_AUDIO æƒé™")
                    _ui.value = _ui.value.copy(error = "è¯·æˆäºˆéº¦å…‹é£æƒé™åå†è¯•")
                    return@launch
                }

                // è¯·æ±‚éŸ³é¢‘ç„¦ç‚¹å¹¶è®¾ç½®é€šä¿¡æ¨¡å¼
                val am = getApplication<Application>().getSystemService(Context.AUDIO_SERVICE) as AudioManager
                val focus = am.requestAudioFocus(
                    AudioManager.OnAudioFocusChangeListener { },
                    AudioManager.STREAM_MUSIC,
                    AudioManager.AUDIOFOCUS_GAIN_TRANSIENT
                )
                Log.i("ChatVM", "[AUDIO_REC] éŸ³é¢‘ç„¦ç‚¹è¯·æ±‚ç»“æœ=$focus")
                try { am.mode = AudioManager.MODE_IN_COMMUNICATION } catch (_: Exception) {}
                try { am.isMicrophoneMute = false } catch (_: Exception) {}

                // ç«‹å³é€‰æ‹©å¯ç”¨çš„(éŸ³æº, é‡‡æ ·ç‡)ç»„åˆ
                val tryRates = intArrayOf(8000, 11025, 16000, 44100, 48000)
                val trySources = intArrayOf(
                    MediaRecorder.AudioSource.MIC,
                    MediaRecorder.AudioSource.VOICE_COMMUNICATION,
                    MediaRecorder.AudioSource.VOICE_RECOGNITION,
                    MediaRecorder.AudioSource.DEFAULT
                )
                var minBuf = 0
                var chosenSource = -1
                var finalRecorder: AudioRecord? = null
                outer@ for (src in trySources) {
                    for (rate in tryRates) {
                        val mb = AudioRecord.getMinBufferSize(
                            rate,
                            AudioFormat.CHANNEL_IN_MONO,
                            AudioFormat.ENCODING_PCM_16BIT
                        )
                        if (mb <= 0) continue
                        val r = AudioRecord(
                            src,
                            rate,
                            AudioFormat.CHANNEL_IN_MONO,
                            AudioFormat.ENCODING_PCM_16BIT,
                            mb * 2
                        )
                        if (r.state == AudioRecord.STATE_INITIALIZED) {
                            finalRecorder = r
                            minBuf = mb
                            phoneSampleRate = rate
                            chosenSource = src
                            break@outer
                        } else {
                            try { r.release() } catch (_: Exception) {}
                        }
                    }
                }
                if (finalRecorder == null) throw IllegalStateException("AudioRecord init failed for all sources+rates")

                val sourceName = when (chosenSource) {
                    MediaRecorder.AudioSource.VOICE_RECOGNITION -> "VOICE_RECOGNITION"
                    MediaRecorder.AudioSource.MIC -> "MIC"
                    MediaRecorder.AudioSource.VOICE_COMMUNICATION -> "VOICE_COMMUNICATION"
                    else -> "DEFAULT"
                }
                Log.i("ChatVM", "[AUDIO_REC] é€‰ç”¨éŸ³æº=$sourceName rate=$phoneSampleRate minBuf=$minBuf")

                phoneRecorder = finalRecorder
                try { finalRecorder.startRecording() } catch (_: Exception) {}
                Log.i("ChatVM", "[AUDIO_REC] startRecording called, state=${finalRecorder.state}, recState=${finalRecorder.recordingState}")
                _ui.value = _ui.value.copy(audioOn = true)
                phoneRecBuffer = ByteArrayOutputStream()

                phoneRecJob = viewModelScope.launch(Dispatchers.IO) {
                    Log.i("ChatVM", "[AUDIO_REC] è¿›å…¥å½•éŸ³è¯»å¾ªç¯")
                    val buf = ByteArray(minBuf * 2)
                    var total = 0
                    val startTs = System.currentTimeMillis()
                    while (this.isActive && finalRecorder.recordingState == AudioRecord.RECORDSTATE_RECORDING) {
                        val read = try {
                            if (android.os.Build.VERSION.SDK_INT >= android.os.Build.VERSION_CODES.M) {
                                finalRecorder.read(buf, 0, buf.size, android.media.AudioRecord.READ_BLOCKING)
                            } else {
                                finalRecorder.read(buf, 0, buf.size)
                            }
                        } catch (e: Exception) { -1 }
                        Log.v("ChatVM", "[AUDIO_REC] loop read=$read state=${finalRecorder.recordingState}")
                        if (read > 0) {
                            phoneRecBuffer?.write(buf, 0, read)
                            total += read
                        } else if (read == 0) {
                            if ((System.currentTimeMillis() - startTs) % 1000L < 50L) {
                                Log.w("ChatVM", "[AUDIO_REC] readè¿”å›0ï¼Œä»åœ¨ç­‰å¾…éŸ³é¢‘... total=$total")
                            }
                        } else {
                            Log.e("ChatVM", "[AUDIO_REC] readè¿”å›é”™è¯¯: $read")
                        }
                        if ((System.currentTimeMillis() - startTs) % 1000L < 50L) {
                            Log.d("ChatVM", "[AUDIO_REC] æ•è·ä¸­: totalBytes=$total")
                        }
                    }
                    Log.i("ChatVM", "[AUDIO_REC] å½•éŸ³è¯»å¾ªç¯ç»“æŸ totalBytes=$total")
                }
            } catch (e: Exception) {
                Log.e("ChatVM", "[AUDIO_REC] å¼€å§‹æ‰‹æœºå½•éŸ³å¤±è´¥", e)
                _ui.value = _ui.value.copy(error = "å¼€å§‹å½•éŸ³å¤±è´¥: ${e.message}")
            }
        }
    }

    // ===== Device recording (BLE) =====
    fun startDeviceRecording() {
        if (deviceRecJob?.isActive == true) return
        if (!_ui.value.bleConnectionState.isConnected) {
            _ui.value = _ui.value.copy(error = "è¯·å…ˆè¿æ¥è“ç‰™è®¾å¤‡åå†è¿›è¡Œè®¾å¤‡å½•éŸ³")
            return
        }
        viewModelScope.launch(Dispatchers.IO) {
            try {
                Log.i("ChatVM", "[ASR_DEV] â–¶ï¸ è®¾å¤‡å½•éŸ³å¼€å§‹")
                ble.startAudioCapture()
                // æ‰“å¼€å…¨å±€å½•éŸ³æŒ‡ç¤ºå™¨ï¼ˆä¸æ‰‹æœºå½•éŸ³å…±ç”¨ï¼‰ï¼Œç”¨äºæ˜¾ç¤ºâ€œå½•éŸ³ä¸­ mm:ssâ€
                _ui.value = _ui.value.copy(audioOn = true)
            } catch (e: Exception) {
                Log.e("ChatVM", "[ASR_DEV] å¼€å§‹è®¾å¤‡å½•éŸ³å¤±è´¥", e)
                _ui.value = _ui.value.copy(error = "å¼€å§‹è®¾å¤‡å½•éŸ³å¤±è´¥: ${e.message}")
            }
        }
    }

    fun stopDeviceRecordingAndSend() {
        viewModelScope.launch(Dispatchers.IO) {
            try {
                Log.i("ChatVM", "[ASR_DEV] ğŸ›‘ åœæ­¢è®¾å¤‡å½•éŸ³å¹¶å‘é€")
                val pcm = ble.stopAudioCapture()
                if (pcm.isEmpty()) {
                    Log.w("ChatVM", "[ASR_DEV] è®¾å¤‡å½•éŸ³ä¸ºç©º")
                    _ui.value = _ui.value.copy(error = "è®¾å¤‡å½•éŸ³ä¸ºç©º")
                    _ui.value = _ui.value.copy(audioOn = false)
                    return@launch
                }
                // OpenGlasså›ºä»¶ä½¿ç”¨16kHz, 16-bit, å•å£°é“PCMï¼Œå°ç«¯åº
                // å›ºä»¶æ¯å¸§160æ ·æœ¬ï¼Œä½†BLEåŒ…å¯èƒ½åŒ…å«å¤šä¸ªå¸§
                Log.i("ChatVM", "[ASR_DEV] ğŸ“Š PCMåŸå§‹æ•°æ®: ${pcm.size} bytes, é¢„æœŸ16kHz 16-bit mono")
                
                // éŸ³é¢‘è´¨é‡æ£€æµ‹
                val audioQuality = analyzeAudioQuality(pcm)
                Log.i("ChatVM", "[ASR_DEV] ğŸµ éŸ³é¢‘è´¨é‡åˆ†æ: $audioQuality")
                
                val cfg = com.example.myapp.settings.Settings.read(getApplication())
                Log.i("ChatVM", "[ASR_DEV] â–¶ï¸ ä½¿ç”¨Baiduè¯†åˆ« devPid=${cfg.baiduDevPid}")
                
                // å°è¯•å¤šç§é‡‡æ ·ç‡ä»¥æé«˜è¯†åˆ«å‡†ç¡®ç‡
                val sampleRates = listOf(16000, 8000, 44100, 22050)
                var finalText = ""
                var bestResult = ""
                
                for (sampleRate in sampleRates) {
                    Log.i("ChatVM", "[ASR_DEV] ğŸ”„ å°è¯•é‡‡æ ·ç‡: ${sampleRate}Hz")
                    val wav = buildWavFromPcm16Mono(pcm, sampleRate)
                    val result = repository.baiduShortSpeech(wav, cfg.baiduApiKey, cfg.baiduSecretKey, cfg.baiduDevPid, sampleRate)
                    
                    result.onSuccess { text ->
                        Log.i("ChatVM", "[ASR_DEV] âœ… ${sampleRate}Hz è¯†åˆ«æˆåŠŸ textLen=${text.length}, text='$text'")
                        if (text.isNotBlank()) {
                            if (text.length > bestResult.length) {
                                bestResult = text
                            }
                            if (finalText.isBlank()) {
                                finalText = text
                            }
                        }
                    }.onFailure { e ->
                        Log.w("ChatVM", "[ASR_DEV] âŒ ${sampleRate}Hz è¯†åˆ«å¤±è´¥: ${e.message}")
                    }
                }
                
                // ä½¿ç”¨æœ€ä½³ç»“æœ
                if (bestResult.isNotBlank()) {
                    finalText = bestResult
                }
                
                if (finalText.isBlank()) {
                    Log.w("ChatVM", "[ASR_DEV] âš ï¸ æ‰€æœ‰é‡‡æ ·ç‡è¯†åˆ«å‡å¤±è´¥")
                    finalText = "éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•"
                }
                
                val reply = ChatMessage(id = System.currentTimeMillis().toString(), role = Role.User, text = "ğŸ“ è®¾å¤‡è¯­éŸ³è½¬å†™: $finalText")
                _ui.value = _ui.value.copy(messages = _ui.value.messages + reply)
                
                if (com.example.myapp.settings.Settings.read(getApplication()).forwardAsrToDoubao && finalText.isNotBlank() && finalText != "éŸ³é¢‘è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•") {
                    try {
                        val live = repository.sendToAi(InputData.Text(finalText), getApplication())
                        val observer = object : Observer<LoadState<AiResponse>> {
                            override fun onChanged(state: LoadState<AiResponse>) {
                                when (state) {
                                    is LoadState.Success -> {
                                        val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
                                        val aiMsg = ChatMessage(id = System.currentTimeMillis().toString(), role = Role.Assistant, text = replyText)
                                        _ui.value = _ui.value.copy(messages = _ui.value.messages + aiMsg)
                                        if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
                                        live.removeObserver(this)
                                    }
                                    is LoadState.Error -> { live.removeObserver(this) }
                                    is LoadState.Loading -> {}
                                }
                            }
                        }
                        viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
                    } catch (_: Exception) {}
                }
            } catch (e: Exception) {
                Log.e("ChatVM", "[ASR_DEV] åœæ­¢è®¾å¤‡å½•éŸ³å¤±è´¥", e)
                _ui.value = _ui.value.copy(error = "åœæ­¢è®¾å¤‡å½•éŸ³å¤±è´¥: ${e.message}")
            } finally {
                // å…³é—­å…¨å±€å½•éŸ³æŒ‡ç¤ºå™¨
                _ui.value = _ui.value.copy(audioOn = false)
            }
        }
    }

    fun stopPhoneRecordingAndSend() {
        viewModelScope.launch(Dispatchers.IO) {
            try {
                Log.i("ChatVM", "[AUDIO_REC] stopPhoneRecordingAndSend invoked")
                // stop and collect
                phoneRecorder?.let { rec ->
                    try { rec.stop() } catch (_: Exception) {}
                    try { rec.release() } catch (_: Exception) {}
                }
                phoneRecorder = null
                phoneRecJob?.cancel()
                val pcmBytes = phoneRecBuffer?.toByteArray() ?: ByteArray(0)
                phoneRecBuffer = null
                _ui.value = _ui.value.copy(audioOn = false)

                Log.i("ChatVM", "[AUDIO_REC] ğŸ›‘ ç»“æŸæ‰‹æœºå½•éŸ³: pcm=${pcmBytes.size} bytes")

                if (pcmBytes.isEmpty()) {
                    Log.w("ChatVM", "[AUDIO_REC] å½•éŸ³ä¸ºç©ºï¼Œå–æ¶ˆå‘é€")
                    _ui.value = _ui.value.copy(error = "å½•éŸ³ä¸ºç©º")
                    return@launch
                }

                // wrap to WAV (PCM16 mono)
                val wav = buildWavFromPcm16Mono(pcmBytes, phoneSampleRate)
                Log.i("ChatVM", "[AUDIO_REC] ğŸ“¦ PCM å°è£…ä¸º WAV: wav=${wav.size} bytes")

                // push user message
                val msg = ChatMessage(
                    id = System.currentTimeMillis().toString(),
                    role = Role.User,
                    text = "ğŸ™ï¸ å‘é€è¯­éŸ³ (${wav.size} bytes)"
                )
                _ui.value = _ui.value.copy(messages = _ui.value.messages + msg, lastAudioTimestampMs = System.currentTimeMillis())

                // send to AI
                val cfg = com.example.myapp.settings.Settings.read(getApplication())
                if (cfg.baiduApiKey.isNotBlank() && cfg.baiduSecretKey.isNotBlank()) {
                    Log.i("ChatVM", "[ASR_BAIDU] â–¶ï¸ å¼€å§‹è¯†åˆ« devPid=${cfg.baiduDevPid}")
                    val result = repository.baiduShortSpeech(wav, cfg.baiduApiKey, cfg.baiduSecretKey, cfg.baiduDevPid, phoneSampleRate)
                    result.onSuccess { text ->
                        Log.i("ChatVM", "[ASR_BAIDU] âœ… è¯†åˆ«æˆåŠŸ textLen=${text.length}")
                        val reply = ChatMessage(id = System.currentTimeMillis().toString(), role = Role.User, text = "ğŸ“ è¯­éŸ³è½¬å†™: $text")
                        _ui.value = _ui.value.copy(messages = _ui.value.messages + reply, error = null)
                        // è‹¥å¼€å¯è½¬å‘åˆ°è±†åŒ…ï¼Œç»§ç»­æŠŠæ–‡æœ¬èµ°AIèŠå¤©
                        if (com.example.myapp.settings.Settings.read(getApplication()).forwardAsrToDoubao && text.isNotBlank()) {
                            try {
                                val live = repository.sendToAi(InputData.Text(text), getApplication())
                                val observer = object : androidx.lifecycle.Observer<LoadState<AiResponse>> {
                                    override fun onChanged(state: LoadState<AiResponse>) {
                                        when (state) {
                                            is LoadState.Success -> {
                                                val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
                                                val aiMsg = ChatMessage(id = System.currentTimeMillis().toString(), role = Role.Assistant, text = replyText)
                                                _ui.value = _ui.value.copy(messages = _ui.value.messages + aiMsg)
                                                if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
                                                live.removeObserver(this)
                                            }
                                            is LoadState.Error -> { live.removeObserver(this) }
                                            is LoadState.Loading -> {}
                                        }
                                    }
                                }
                                viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
                            } catch (_: Exception) {}
                        }
                    }.onFailure {
                        Log.e("ChatVM", "[ASR_BAIDU] âŒ è¯†åˆ«å¤±è´¥", it)
                        _ui.value = _ui.value.copy(error = "Baidu è¯†åˆ«å¤±è´¥: ${it.message}")
                    }
                } else {
                    Log.i("ChatVM", "[ASR_BAIDU] âš ï¸ æœªé…ç½®Baiduå¯†é’¥ï¼Œå·²ç§»é™¤AUCï¼Œæ— æ³•è¯†åˆ«")
                    try {
                        val filename = "speech_${System.currentTimeMillis()}.wav"
                        val urlResult = com.example.myapp.utils.HttpUpload.uploadPublicUrl(wav, filename)
                        val url = urlResult.getOrThrow()
                        Log.i("ChatVM", "[ASR_BAIDU] ğŸŒ å·²ä¸Šä¼ åˆ°ä¸´æ—¶URLï¼š$urlï¼ˆä»…è°ƒè¯•ï¼‰")
                        _ui.value = _ui.value.copy(error = "å·²ç§»é™¤AUCæµç¨‹ï¼Œè¯·åœ¨è®¾ç½®ä¸­å¡«å†™Baiduä¿¡æ¯ä½¿ç”¨è¯­éŸ³è¯†åˆ«")
                    } catch (e: Exception) {
                        Log.e("ChatVM", "[ASR_BAIDU] ä¸Šä¼ è°ƒè¯•URLå¤±è´¥", e)
                        _ui.value = _ui.value.copy(error = "éŸ³é¢‘ä¸Šä¼ æˆ–AUCè°ƒç”¨å¤±è´¥: ${e.message}")
                    }
                }
            } catch (e: Exception) {
                Log.e("ChatVM", "[AUDIO_REC] åœæ­¢æ‰‹æœºå½•éŸ³å¹¶å‘é€å¤±è´¥", e)
                _ui.value = _ui.value.copy(error = "åœæ­¢å½•éŸ³å¤±è´¥: ${e.message}")
            }
        }
    }

    private fun buildWavFromPcm16Mono(pcm: ByteArray, sampleRate: Int): ByteArray {
        val totalDataLen = pcm.size + 36
        val byteRate = sampleRate * 2 // mono, 16-bit
        val header = ByteBuffer.allocate(44).order(ByteOrder.LITTLE_ENDIAN)
        // RIFF chunk descriptor
        header.put("RIFF".toByteArray())
        header.order(ByteOrder.LITTLE_ENDIAN).putInt(totalDataLen)
        header.put("WAVE".toByteArray())
        // fmt sub-chunk
        header.put("fmt ".toByteArray())
        header.putInt(16) // Subchunk1Size for PCM
        header.putShort(1) // AudioFormat PCM
        header.putShort(1) // NumChannels = 1
        header.putInt(sampleRate)
        header.putInt(byteRate)
        header.putShort(2) // BlockAlign = NumChannels * BitsPerSample/8
        header.putShort(16) // BitsPerSample
        // data sub-chunk
        header.put("data".toByteArray())
        header.putInt(pcm.size)
        val out = ByteArrayOutputStream()
        out.write(header.array())
        out.write(pcm)
        return out.toByteArray()
	}

	fun switchCamera() {
		viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				// camera.switchCamera()
				_ui.value = _ui.value.copy(error = "åˆ‡æ¢ç›¸æœºåŠŸèƒ½æš‚æœªå®ç°")
			}.onFailure { e -> _ui.value = _ui.value.copy(error = "åˆ‡æ¢ç›¸æœºå¤±è´¥: ${e.message}") }
		}
	}

	fun scanBleDevices() {
		// å¯åŠ¨è“ç‰™æ‰«æå’Œè¿æ¥
		setBleEnabled(true)
	}

	fun clearMessages() {
		_ui.value = _ui.value.copy(messages = emptyList())
	}

	fun deleteMessage(messageId: String) {
		_ui.value = _ui.value.copy(
			messages = _ui.value.messages.filter { it.id != messageId }
		)
	}

	fun resendMessage(messageId: String) {
		val message = _ui.value.messages.find { it.id == messageId }
		message?.let {
			// é‡æ–°å‘é€æ¶ˆæ¯
			val newMessage = ChatMessage(
				id = System.currentTimeMillis().toString(),
				role = it.role,
				text = it.text
			)
			_ui.value = _ui.value.copy(messages = _ui.value.messages + newMessage)
			
			// å‘é€ç»™AIå¤„ç†
				viewModelScope.launch(Dispatchers.IO) {
				try {
						val live = repository.sendToAi(InputData.Text(it.text), getApplication())
						val observer = object : Observer<LoadState<AiResponse>> {
							override fun onChanged(state: LoadState<AiResponse>) {
								when (state) {
									is LoadState.Success -> {
										val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
									val reply = ChatMessage(
										id = System.currentTimeMillis().toString(),
										role = Role.Assistant,
										text = replyText
									)
										_ui.value = _ui.value.copy(messages = _ui.value.messages + reply)
										if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
										live.removeObserver(this)
									}
								is LoadState.Error -> {
									_ui.value = _ui.value.copy(error = "AIå¤„ç†å¤±è´¥: ${state.throwable.message}")
									live.removeObserver(this)
								}
								is LoadState.Loading -> {
									Log.d("ChatViewModel", "AIå¤„ç†ä¸­...")
								}
								}
							}
						}
						viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
				} catch (e: Exception) {
					_ui.value = _ui.value.copy(error = "AIå¤„ç†å¼‚å¸¸: ${e.message}")
				}
			}
		}
	}

	fun sendMessage(text: String) {
		if (text.isBlank()) return
		
		val message = ChatMessage(
			id = System.currentTimeMillis().toString(),
			role = Role.User,
			text = text
		)
		_ui.value = _ui.value.copy(messages = _ui.value.messages + message, inputText = "")
		
		// å‘é€ç»™AIå¤„ç†
		viewModelScope.launch(Dispatchers.IO) {
			try {
				val live = repository.sendToAi(InputData.Text(text), getApplication())
				val observer = object : Observer<LoadState<AiResponse>> {
					override fun onChanged(state: LoadState<AiResponse>) {
						when (state) {
							is LoadState.Success -> {
								val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
								val reply = ChatMessage(
									id = System.currentTimeMillis().toString(),
									role = Role.Assistant,
									text = replyText
								)
								_ui.value = _ui.value.copy(messages = _ui.value.messages + reply)
								if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
								live.removeObserver(this)
							}
							is LoadState.Error -> {
								_ui.value = _ui.value.copy(error = "AIå¤„ç†å¤±è´¥: ${state.throwable.message}")
								live.removeObserver(this)
							}
							is LoadState.Loading -> {
								Log.d("ChatViewModel", "AIå¤„ç†ä¸­...")
							}
						}
					}
				}
				viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
			} catch (e: Exception) {
				_ui.value = _ui.value.copy(error = "AIå¤„ç†å¼‚å¸¸: ${e.message}")
			}
		}
	}

	fun startCameraLoop() {
		cameraJob?.cancel()
		cameraJob = viewModelScope.launch(Dispatchers.IO) {
			runCatching {
				camera.periodicJpegFlow(intervalMs = 5000L).collect { photo ->
					_ui.value = _ui.value.copy(lastImageTimestampMs = System.currentTimeMillis())
					val message = ChatMessage(
						id = System.currentTimeMillis().toString(),
						role = Role.User,
						text = "ğŸ“· æ‰‹æœºæ‹ç…§ (${photo.size} bytes)"
					)
					_ui.value = _ui.value.copy(messages = _ui.value.messages + message)
					// å‘é€å›¾ç‰‡ç»™AIå¤„ç†
					try {
						val live = repository.sendToAi(InputData.Image(photo), getApplication())
						val observer = object : Observer<LoadState<AiResponse>> {
							override fun onChanged(state: LoadState<AiResponse>) {
								when (state) {
									is LoadState.Success -> {
										val replyText = state.data.choices?.firstOrNull()?.message?.content ?: ""
										val reply = ChatMessage(
											id = System.currentTimeMillis().toString(),
											role = Role.Assistant,
											text = replyText
										)
										_ui.value = _ui.value.copy(messages = _ui.value.messages + reply)
										if (replyText.isNotBlank() && _ui.value.ttsOn) tts.speak(replyText)
										live.removeObserver(this)
									}
									is LoadState.Error -> {
										_ui.value = _ui.value.copy(error = "AIå¤„ç†å¤±è´¥: ${state.throwable.message}")
										live.removeObserver(this)
									}
									is LoadState.Loading -> {
										Log.d("ChatViewModel", "AIå¤„ç†ä¸­...")
									}
								}
							}
						}
						viewModelScope.launch(Dispatchers.Main) { live.observeForever(observer) }
					} catch (e: Exception) {
						_ui.value = _ui.value.copy(error = "AIå¤„ç†å¼‚å¸¸: ${e.message}")
					}
				}
			}.onFailure { e ->
				_ui.value = _ui.value.copy(error = "ç›¸æœºå¾ªç¯å¯åŠ¨å¤±è´¥: ${e.message}")
			}
		}
	}

	fun stopCameraLoop() {
		cameraJob?.cancel()
		cameraJob = null
	}
	
	// éŸ³é¢‘è´¨é‡åˆ†æå‡½æ•°
	private fun analyzeAudioQuality(pcm: ByteArray): String {
		if (pcm.size < 4) return "æ•°æ®è¿‡çŸ­"
		
		val samples = pcm.size / 2 // 16-bit = 2 bytes per sample
		val duration = samples / 16000.0 // å‡è®¾16kHzé‡‡æ ·ç‡
		
		// è®¡ç®—éŸ³é¢‘ç»Ÿè®¡ä¿¡æ¯
		var sum = 0.0
		var maxAmplitude = 0.0
		var zeroCrossings = 0
		
		for (i in 0 until pcm.size - 1 step 2) {
			val sample = (pcm[i + 1].toInt() shl 8) or (pcm[i].toInt() and 0xFF)
			val amplitude = kotlin.math.abs(sample.toDouble())
			
			sum += amplitude
			if (amplitude > maxAmplitude) maxAmplitude = amplitude
			
			// æ£€æµ‹è¿‡é›¶ç‚¹
			if (i > 0) {
				val prevSample = (pcm[i - 1].toInt() shl 8) or (pcm[i - 2].toInt() and 0xFF)
				if ((prevSample < 0 && sample >= 0) || (prevSample >= 0 && sample < 0)) {
					zeroCrossings++
				}
			}
		}
		
		val avgAmplitude = sum / samples
		val dynamicRange = if (avgAmplitude > 0) 20 * kotlin.math.log10(maxAmplitude / avgAmplitude) else 0.0
		val frequency = if (duration > 0) zeroCrossings / (2.0 * duration) else 0.0
		
		return "æ—¶é•¿=${String.format("%.2f", duration)}s, æ ·æœ¬æ•°=$samples, " +
			   "å¹³å‡å¹…åº¦=${String.format("%.0f", avgAmplitude)}, " +
			   "æœ€å¤§å¹…åº¦=${String.format("%.0f", maxAmplitude)}, " +
			   "åŠ¨æ€èŒƒå›´=${String.format("%.1f", dynamicRange)}dB, " +
			   "ä¸»é¢‘=${String.format("%.0f", frequency)}Hz"
	}
}


